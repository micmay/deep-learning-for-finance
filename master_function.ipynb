{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "\u2193\u2193\u2193\u2193\u2193\u2193\u2193\u2193\u2193IMPORTANT READ FIRST\u2193\u2193\u2193\u2193\u2193\u2193\u2193\u2193\u2193\n",
        "||||||||||||||||||||||||||||||||||||||||\n",
        "\n",
        "To properly use this file, please use the following guidelines:\n",
        "    \n",
        "    1. Put this file in the directory used by the interpreter\n",
        "    2. In SPYDER, the directory is generally on the top right\n",
        "    3. Alternatively, you can open this file and execute it\n",
        "\n",
        "PUT THIS FILE IN THE PYTHON DIRECTORY IN ORDER TO PROPERLY IMPORT ITS FUNCTIONS\n",
        "\n",
        "||||||||||||||||||||||||||||||||||||||||\n",
        "\u2191\u2191\u2191\u2191\u2191\u2191\u2191\u2191\u2191IMPORTANT READ FIRST\u2191\u2191\u2191\u2191\u2191\u2191\u2191\u2191\u2191\n",
        "'''\n",
        "\n",
        "import datetime\n",
        "import pytz\n",
        "import pandas                    as pd\n",
        "import MetaTrader5               as mt5\n",
        "import matplotlib.pyplot         as plt\n",
        "import numpy                     as np\n",
        "import cot_reports               as cot\n",
        "import requests\n",
        "import json  \n",
        "\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "assets = ['EURUSD', 'USDCHF', 'GBPUSD', 'USDCAD', 'AUDUSD', 'NZDUSD', 'EURGBP', 'EURCHF', 'EURCAD', 'EURAUD']\n",
        " \n",
        "def get_quotes(time_frame, year = 2005, month = 1, day = 1, asset = \"EURUSD\"):    \n",
        "    if not mt5.initialize(): \n",
        "        print(\"initialize() failed, error code =\", mt5.last_error()) \n",
        "        quit()\n",
        "    timezone = pytz.timezone(\"Europe/Paris\")\n",
        "    time_from = datetime.datetime(year, month, day, tzinfo = timezone)\n",
        "    time_to = datetime.datetime.now(timezone) + datetime.timedelta(days=1)\n",
        "    rates = mt5.copy_rates_range(asset, time_frame, time_from, time_to)\n",
        "    rates_frame = pd.DataFrame(rates)\n",
        "    \n",
        "    return rates_frame    \n",
        "\n",
        "def mass_import(asset, time_frame):\n",
        "    if time_frame == 'M15':\n",
        "        data = get_quotes(mt5.TIMEFRAME_M15, 2023, 6, 1, asset = assets[asset])\n",
        "        data = data.iloc[:, 1:5].values\n",
        "        data = data.round(decimals = 5)    \n",
        "    if time_frame == 'M30':\n",
        "        data = get_quotes(mt5.TIMEFRAME_M30, 2023, 6, 1, asset = assets[asset])\n",
        "        data = data.iloc[:, 1:5].values\n",
        "        data = data.round(decimals = 5)              \n",
        "    if time_frame == 'H1':\n",
        "        data = get_quotes(mt5.TIMEFRAME_H1, 2015, 1, 1, asset = assets[asset])\n",
        "        data = data.iloc[:, 1:5].values\n",
        "        data = data.round(decimals = 5)         \n",
        "    if time_frame == 'D1':\n",
        "        data = get_quotes(mt5.TIMEFRAME_D1, 2003, 1, 1, asset = assets[asset])\n",
        "        data = data.iloc[:, 1:5].values\n",
        "        data = data.round(decimals = 5)        \n",
        "    if time_frame == 'W1':\n",
        "        data = get_quotes(mt5.TIMEFRAME_W1, 2002, 1, 1, asset = assets[asset])\n",
        "        data = data.iloc[:, 1:5].values\n",
        "        data = data.round(decimals = 5)        \n",
        "    if time_frame == 'M1':\n",
        "        data = get_quotes(mt5.TIMEFRAME_MN1, 2000, 1, 1, asset = assets[asset])\n",
        "        data = data.iloc[:, 1:5].values\n",
        "        data = data.round(decimals = 5)             \n",
        "    \n",
        "    return data \n",
        "\n",
        "def data_preprocessing(data, num_lags, train_test_split):\n",
        "    # Prepare the data for training\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(len(data) - num_lags):\n",
        "        x.append(data[i:i + num_lags])\n",
        "        y.append(data[i+ num_lags])\n",
        "    # Convert the data to numpy arrays\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    # Split the data into training and testing sets\n",
        "    split_index = int(train_test_split * len(x))\n",
        "    x_train = x[:split_index]\n",
        "    y_train = y[:split_index]\n",
        "    x_test = x[split_index:]\n",
        "    y_test = y[split_index:]\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "def recursive_mpf(x_test, y_test, num_lags, model, architecture = 'MLP'):\n",
        "    if architecture == 'MLP':\n",
        "        # Latest values to use as inputs\n",
        "        x_test = x_test[-1]\n",
        "        x_test = np.reshape(x_test, (-1, 1))\n",
        "        x_test = np.transpose(x_test)\n",
        "        y_predicted = []\n",
        "        for i in range(len(y_test)):     \n",
        "            # Predict over the last x_test values\n",
        "            predicted_value = model.predict(x_test)\n",
        "            y_predicted = np.append(y_predicted, predicted_value)\n",
        "            # Re-inserting the latest prediction into x_test array\n",
        "            x_test = np.transpose(x_test)\n",
        "            x_test = np.append(x_test, predicted_value)\n",
        "            x_test = x_test[1:, ]\n",
        "            x_test = np.reshape(x_test, (-1, 1))\n",
        "            x_test = np.transpose(x_test)\n",
        "        y_predicted = np.reshape(y_predicted, (-1, 1))\n",
        "    elif architecture == 'LSTM':\n",
        "        # Latest values to use as inputs\n",
        "        x_test = x_test[-1]\n",
        "        x_test = np.reshape(x_test, (-1, 1))\n",
        "        x_test = np.transpose(x_test)\n",
        "        x_test = x_test.reshape((-1, num_lags, 1))\n",
        "        y_predicted = []\n",
        "        for i in range(len(y_test)):     \n",
        "            # Predict over the last x_test values\n",
        "            predicted_value = model.predict(x_test)\n",
        "            y_predicted = np.append(y_predicted, predicted_value)\n",
        "            # Re-inserting the latest prediction into x_test array\n",
        "            x_test = np.transpose(x_test)\n",
        "            x_test = np.append(x_test, predicted_value)\n",
        "            x_test = x_test[1:, ]\n",
        "            x_test = np.reshape(x_test, (-1, 1))\n",
        "            x_test = np.transpose(x_test)\n",
        "            x_test = x_test.reshape((-1, num_lags, 1))  \n",
        "        y_predicted = np.reshape(y_predicted, (-1, 1))\n",
        "        \n",
        "    return x_test, y_predicted\n",
        "\n",
        "def direct_mpf(data, num_lags, train_test_split, forecast_horizon):\n",
        "    x, y = [], []\n",
        "    for i in range(len(data) - num_lags - forecast_horizon + 1):\n",
        "        x.append(data[i:i + num_lags])\n",
        "        y.append(data[i + num_lags:i + num_lags + forecast_horizon])\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)   \n",
        "    split_index = int(train_test_split * len(x))\n",
        "    x_train, x_test = x[:split_index], x[split_index:]\n",
        "    y_train, y_test = y[:split_index], y[split_index:] \n",
        "    \n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "def import_cot_data(start_year, end_year, market):\n",
        "    df = pd.DataFrame()\n",
        "    for i in range(start_year, end_year + 1):\n",
        "        single_year = pd.DataFrame(cot.cot_year(i, cot_report_type='traders_in_financial_futures_fut')) \n",
        "        df = pd.concat([single_year, df], ignore_index=True)\n",
        "    new_df = df.loc[:, ['Market_and_Exchange_Names',\n",
        "                        'Report_Date_as_YYYY-MM-DD',\n",
        "                        'Pct_of_OI_Dealer_Long_All',\n",
        "                        'Pct_of_OI_Dealer_Short_All',\n",
        "                        'Pct_of_OI_Lev_Money_Long_All',                    \n",
        "                        'Pct_of_OI_Lev_Money_Short_All']]\n",
        "    new_df['Report_Date_as_YYYY-MM-DD'] = pd.to_datetime(new_df['Report_Date_as_YYYY-MM-DD'])\n",
        "    new_df = new_df.sort_values(by='Report_Date_as_YYYY-MM-DD')\n",
        "    data = new_df[new_df['Market_and_Exchange_Names'] == market]\n",
        "    data['Net_COT'] = (data['Pct_of_OI_Lev_Money_Long_All'] - \\\n",
        "                       data['Pct_of_OI_Lev_Money_Short_All']) - \\\n",
        "                      (data['Pct_of_OI_Dealer_Long_All'] -\\\n",
        "                       data['Pct_of_OI_Dealer_Short_All'])                \n",
        "    \n",
        "    return data\n",
        "\n",
        "def plot_train_test_values(window, train_window, y_train, y_test, y_predicted):\n",
        "    prediction_window = window\n",
        "    first = train_window\n",
        "    second = window - first\n",
        "    y_predicted = np.reshape(y_predicted, (-1, 1))\n",
        "    y_test = np.reshape(y_test, (-1, 1))\n",
        "    plotting_time_series = np.zeros((prediction_window, 3))\n",
        "    plotting_time_series[0:first, 0] = y_train[-first:]\n",
        "    plotting_time_series[first:, 1] = y_test[0:second, 0]\n",
        "    plotting_time_series[first:, 2] = y_predicted[0:second, 0] \n",
        "    plotting_time_series[0:first, 1] = np.nan\n",
        "    plotting_time_series[0:first, 2] = np.nan\n",
        "    plotting_time_series[first:, 0] = np.nan\n",
        "    plt.plot(plotting_time_series[:, 0], label = 'Training data', color = 'black', linewidth = 2.5)\n",
        "    plt.plot(plotting_time_series[:, 1], label = 'Test data', color = 'black', linestyle = 'dashed', linewidth = 2)\n",
        "    plt.plot(plotting_time_series[:, 2], label = 'Predicted data', color = 'red', linewidth = 1)\n",
        "    plt.axvline(x = first, color = 'black', linestyle = '--', linewidth = 1)\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "\n",
        "def forecasting_threshold(predictions, threshold):\n",
        "    for i in range(len(predictions)):\n",
        "        if predictions[i] > threshold:\n",
        "            predictions[i] = predictions[i]\n",
        "        elif predictions[i] < -threshold:\n",
        "            predictions[i] = predictions[i]\n",
        "        else:\n",
        "            predictions[i] = 0\n",
        "    return predictions\n",
        "\n",
        "def calculate_accuracy(predicted_returns, real_returns):\n",
        "    predicted_returns = np.reshape(predicted_returns, (-1, 1))\n",
        "    real_returns = np.reshape(real_returns, (-1, 1))\n",
        "    hits = sum((np.sign(predicted_returns)) == np.sign(real_returns))\n",
        "    total_samples = len(predicted_returns)\n",
        "    accuracy = hits / total_samples\n",
        "    \n",
        "    return accuracy[0] * 100\n",
        "\n",
        "def model_bias(predicted_returns):\n",
        "    bullish_forecasts = np.sum(predicted_returns > 0)\n",
        "    bearish_forecasts = np.sum(predicted_returns < 0)\n",
        "    \n",
        "    return bullish_forecasts / bearish_forecasts\n",
        "\n",
        "def calculate_directional_accuracy(predicted_returns, real_returns):\n",
        "    # Calculate differences between consecutive elements\n",
        "    diff_predicted = np.diff(predicted_returns, axis = 0)\n",
        "    diff_real = np.diff(real_returns, axis = 0)\n",
        "    # Check if signs of differences are the same\n",
        "    store = []  \n",
        "    for i in range(len(predicted_returns)):\n",
        "        try:            \n",
        "            if np.sign(diff_predicted[i]) == np.sign(diff_real[i]):                \n",
        "                store = np.append(store, 1)        \n",
        "            elif np.sign(diff_predicted[i]) != np.sign(diff_real[i]):                \n",
        "                store = np.append(store, 0)                  \n",
        "        except IndexError:           \n",
        "            pass       \n",
        "    directional_accuracy = np.sum(store) / len(store)\n",
        "        \n",
        "    return directional_accuracy * 100\n",
        "\n",
        "def import_crypto(symbol, interval = '1h'): \n",
        "    # Getting the original link from Binance\n",
        "    url = 'https://api.binance.com/api/v1/klines'\n",
        "    # Linking the link with the Cryptocurrency and the time frame\n",
        "    link = url + '?symbol=' + symbol + '&interval=' + interval\n",
        "    # Requesting the data in the form of text\n",
        "    data = json.loads(requests.get(link).text)\n",
        "    # Converting the text data to dataframe\n",
        "    data = np.array(data)\n",
        "    data = data.astype(np.float)\n",
        "    data = data[:, 1:5]\n",
        "    \n",
        "    return data\n",
        "\n",
        "def multiple_data_preprocessing(data, train_test_split):\n",
        "    data = add_column(data, 4)\n",
        "    data[:, 1] = np.roll(data[:, 1], 1, axis = 0)\n",
        "    data[:, 2] = np.roll(data[:, 2], 1, axis = 0)\n",
        "    data[:, 3] = np.roll(data[:, 1], 1, axis = 0)\n",
        "    data[:, 4] = np.roll(data[:, 2], 1, axis = 0)\n",
        "    data[:, 5] = np.roll(data[:, 3], 1, axis = 0)\n",
        "    data[:, 6] = np.roll(data[:, 4], 1, axis = 0)\n",
        "    data = data[1:, ]\n",
        "    x = data[:, 1:]\n",
        "    y = data[:, 0]\n",
        "    split_index = int(train_test_split * len(x))\n",
        "    x_train = x[:split_index]\n",
        "    y_train = y[:split_index]\n",
        "    x_test = x[split_index:]\n",
        "    y_test = y[split_index:]\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "def volatility(data, lookback, close, position):\n",
        "    data = add_column(np.reshape(data, (-1, 1)), 1)\n",
        "    for i in range(len(data)):   \n",
        "        try:           \n",
        "            data[i, position] = (data[i - lookback + 1:i + 1, close].std())  \n",
        "        except IndexError:          \n",
        "            pass   \n",
        "    data = delete_row(data, lookback)    \n",
        "     \n",
        "    return data\n",
        "\n",
        "def add_column(data, times): \n",
        "    for i in range(1, times + 1): \n",
        "        new = np.zeros((len(data), 1), dtype = float)     \n",
        "        data = np.append(data, new, axis = 1)\n",
        "        \n",
        "    return data\n",
        "\n",
        "def delete_column(data, index, times):  \n",
        "    for i in range(1, times + 1):   \n",
        "        data = np.delete(data, index, axis = 1)\n",
        "\n",
        "    return data\n",
        "\n",
        "def delete_row(data, number): \n",
        "    data = data[number:, ]\n",
        "    \n",
        "    return data\n",
        "\n",
        "def compute_diff(data, period):\n",
        "    data = add_column(np.reshape(data, (-1, 1)), 1)\n",
        "    for i in range(len(data)):\n",
        "        data[i, -1] = data[i, 0] - data[i - 1, 0]\n",
        "    data = delete_column(data, 0, 1)\n",
        "    \n",
        "    return data\n",
        "\n",
        "def ma(data, lookback, close, position):     \n",
        "    data = add_column(data, 1)    \n",
        "    for i in range(len(data)):           \n",
        "            try:                \n",
        "                data[i, position] = (data[i - lookback + 1:i + 1, close].mean())            \n",
        "            except IndexError:               \n",
        "                pass           \n",
        "    data = delete_row(data, lookback)\n",
        "    \n",
        "    return data\n",
        "\n",
        "def smoothed_ma(data, alpha, lookback, close, position):    \n",
        "    lookback = (2 * lookback) - 1    \n",
        "    alpha = alpha / (lookback + 1.0)    \n",
        "    beta  = 1 - alpha    \n",
        "    data = ma(data, lookback, close, position)\n",
        "    data[lookback + 1, position] = (data[lookback + 1, close] * alpha) + (data[lookback, position] * beta)\n",
        "    for i in range(lookback + 2, len(data)):\n",
        "            try:\n",
        "                data[i, position] = (data[i, close] * alpha) + (data[i - 1, position] * beta)\n",
        "            except IndexError:\n",
        "                pass\n",
        "            \n",
        "    return data\n",
        "\n",
        "def rsi(data, lookback, close, position):\n",
        "    data = add_column(data, 5)\n",
        "    for i in range(len(data)): \n",
        "        data[i, position] = data[i, close] - data[i - 1, close]\n",
        "    for i in range(len(data)):\n",
        "        if data[i, position] > 0:\n",
        "            data[i, position + 1] = data[i, position]\n",
        "        elif data[i, position] < 0:       \n",
        "            data[i, position + 2] = abs(data[i, position])         \n",
        "    data = smoothed_ma(data, 2, lookback, position + 1, position + 3)\n",
        "    data = smoothed_ma(data, 2, lookback, position + 2, position + 4)\n",
        "    data[:, position + 5] = data[:, position + 3] / data[:, position + 4]   \n",
        "    data[:, position + 6] = (100 - (100 / (1 + data[:, position + 5])))\n",
        "    data = delete_column(data, position, 6)\n",
        "    data = delete_row(data, lookback)\n",
        "\n",
        "    return data"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}